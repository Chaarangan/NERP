torch:
    device: "cpu"
    seed:
data:
    train_data: '/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/train.csv'
    valid_data: '/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/devel.csv'
    train_valid_split: 0.2
    test_data: ['/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/test.csv']
    parameters:
        sep:
        quoting:
        shuffle:
    limit: 10
    tags: ["B-SO", "B-GGP", "B-Taxon", "B-CHEBI", "B-CL", "B-GO", "I-SO", "I-GGP", "I-Taxon", "I-CHEBI", "I-CL", "I-GO"]
model: 
    archi: "bilstm-crf"
    max_len: 128 
    dropout: 0.1
    num_workers: 
    hyperparameters:
        epochs: 1
        warmup_steps: 500
        train_batch_size: 64
        valid_batch_size: 8
        lr: 0.0001
    tokenizer_parameters: 
        do_lower_case: False
    pretrained_models: 
        - Charangan/MedBERT
training:
    continue_from_checkpoint: False
    checkpoint_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/model.bin"
    checkpoint_tokenizer_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/tokenizer"
    output_dir: "models/"
    o_tag_cr: True
    return_accuracy: False
kfold: 
    is_kfold: False
    splits: 2
    test_on_original: False
inference:
    pretrained: "Charangan/MedBERT"
    model_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/model.bin"
    tokenizer_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/tokenizer"
    in_file_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/data/test copy.csv"
    out_file_path: "/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/output.csv"