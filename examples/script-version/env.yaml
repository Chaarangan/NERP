torch:
    device: "cpu"
data:
    train: '/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/train.csv'
    valid: '/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/devel.csv'
    train_valid_split: 0.2
    test: ['/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/test.csv']
    parameters:
        sep:
        quoting:
        shuffle:
    limit: 10
    tags: ["B-SO", "B-GGP", "B-Taxon", "B-CHEBI", "B-CL", "B-GO", "I-SO", "I-GGP", "I-Taxon", "I-CHEBI", "I-CL", "I-GO"]

model: 
    archi: "bilstm-crf"
    max_len: 128 
    dropout: 0.1
    num_workers: 
    hyperparameters:
        epochs: 1
        warmup_steps: 500
        batch_size: 
            train: 64
            valid: 64
        lr: 0.0001
        seed: 
    tokenizer_parameters: 
        do_lower_case: False
    pretrained_models: 
        - Charangan/MedBERT

train:
    existing_model_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/model.bin"
    existing_tokenizer_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/tokenizer"
    output_dir: "models/"
    o_tag_cr: True

kfold: 
    splits: 2
    seed: 42
    test_on_original: False

inference:
    pretrained: "Charangan/MedBERT"
    model_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/model.bin"
    tokenizer_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/models1/MedBERT/tokenizer"
    bulk:
        in_file_path: "/Users/charangan/Documents/Intern/open-source/NERP checking/data/test copy.csv"
        out_file_path: "/Users/charangan/Documents/Intern/NER/datasets/data/CRAFT/CRAFT-IOB/output.csv"
    individual:
        text: "Hello from NERP"
    max_len: 128 